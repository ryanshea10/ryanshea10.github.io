<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2022-06-23T15:46:19-04:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Ryan Shea</title><subtitle>DREAM Project</subtitle><entry><title type="html">Week 4</title><link href="http://localhost:4000/week4/" rel="alternate" type="text/html" title="Week 4" /><published>2022-06-17T00:00:00-04:00</published><updated>2022-06-17T00:00:00-04:00</updated><id>http://localhost:4000/week4</id><content type="html" xml:base="http://localhost:4000/week4/"><![CDATA[<p>I spent week 4 creating hybrid chatbots which combine responses from the template bots as well as model-based chatbots. The model-based chatbot that I used to create these hybrid bots was Meta’s BlenderBot. The initial implementation of these bots is fairly simple, after certain states in the template BlenderBot will take over for a few turns and chat with the user. Then the template bot will jump back in to steer the conversation back onto the topic for the textbook unit. There are still some issues with this implementation which mostly have to do with the bot’s memory. BlenderBot currently does not have access to the phrases uttered by the template bot and therefore does not have the complete context for the conversation. There are also some issues with it retaining memory from previous chats which also cause some issues. My future work will involve fixing these issues and improving the incorporation of model-based bots.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[I spent week 4 creating hybrid chatbots which combine responses from the template bots as well as model-based chatbots. The model-based chatbot that I used to create these hybrid bots was Meta’s BlenderBot. The initial implementation of these bots is fairly simple, after certain states in the template BlenderBot will take over for a few turns and chat with the user. Then the template bot will jump back in to steer the conversation back onto the topic for the textbook unit. There are still some issues with this implementation which mostly have to do with the bot’s memory. BlenderBot currently does not have access to the phrases uttered by the template bot and therefore does not have the complete context for the conversation. There are also some issues with it retaining memory from previous chats which also cause some issues. My future work will involve fixing these issues and improving the incorporation of model-based bots.]]></summary></entry><entry><title type="html">Week 3</title><link href="http://localhost:4000/week3/" rel="alternate" type="text/html" title="Week 3" /><published>2022-06-10T00:00:00-04:00</published><updated>2022-06-10T00:00:00-04:00</updated><id>http://localhost:4000/week3</id><content type="html" xml:base="http://localhost:4000/week3/"><![CDATA[<p>I spent the third week incorporating acknowledgments into the template bots I made in the previous week. The bots are capable of extracting different natural language features from user responses using a combination of regular expressions and existing APIs. The language features are then used to generate different responses, if no usable features are present then the bot falls back to a set of default acknowledments. I also added a feature that allows the bot to move between units depending on the user’s input. This was actually the most difficult thing I did during the week since I had to add new variables in such a way that they didn’t affect the front-end or back-end of the web app.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[I spent the third week incorporating acknowledgments into the template bots I made in the previous week. The bots are capable of extracting different natural language features from user responses using a combination of regular expressions and existing APIs. The language features are then used to generate different responses, if no usable features are present then the bot falls back to a set of default acknowledments. I also added a feature that allows the bot to move between units depending on the user’s input. This was actually the most difficult thing I did during the week since I had to add new variables in such a way that they didn’t affect the front-end or back-end of the web app.]]></summary></entry><entry><title type="html">Week 2</title><link href="http://localhost:4000/week2/" rel="alternate" type="text/html" title="Week 2" /><published>2022-06-03T00:00:00-04:00</published><updated>2022-06-03T00:00:00-04:00</updated><id>http://localhost:4000/week2</id><content type="html" xml:base="http://localhost:4000/week2/"><![CDATA[<p>In the second week of my project I created the templates that the chatbots were to be built on. These templates were based on example sentences from two different English textbooks used by Japanese colleges. Each unit had a seperate template so in total I created 17 different templates. The hardest part about this week was thinking of different sentence variations and conversation branches. Each template needs to have variability so that students can have their own experiences with the bots and talk to them multiple times without it getting too repetitive. It was sometimes difficult to create this variability while still staying on topic with the textbook units.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[In the second week of my project I created the templates that the chatbots were to be built on. These templates were based on example sentences from two different English textbooks used by Japanese colleges. Each unit had a seperate template so in total I created 17 different templates. The hardest part about this week was thinking of different sentence variations and conversation branches. Each template needs to have variability so that students can have their own experiences with the bots and talk to them multiple times without it getting too repetitive. It was sometimes difficult to create this variability while still staying on topic with the textbook units.]]></summary></entry><entry><title type="html">Week 1</title><link href="http://localhost:4000/week1/" rel="alternate" type="text/html" title="Week 1" /><published>2022-05-27T00:00:00-04:00</published><updated>2022-05-27T00:00:00-04:00</updated><id>http://localhost:4000/week1</id><content type="html" xml:base="http://localhost:4000/week1/"><![CDATA[<p>During the first week of my work I mostly spent my time familiarizing myself with the codebase that I would be working with. A general framework for the chatbots had already been established which I needed to understand so that I could fully flesh out the chatbots and add new features. The biggest challenge for me was actually just getting the python debugger in VS Code to work in different virtual environments. By default the debugger kept switching to the base envirnment and therefore couldn’t import the correct packages. After I got that working I was easily able to step through the program and figure out how the codebase was operating.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[During the first week of my work I mostly spent my time familiarizing myself with the codebase that I would be working with. A general framework for the chatbots had already been established which I needed to understand so that I could fully flesh out the chatbots and add new features. The biggest challenge for me was actually just getting the python debugger in VS Code to work in different virtual environments. By default the debugger kept switching to the base envirnment and therefore couldn’t import the correct packages. After I got that working I was easily able to step through the program and figure out how the codebase was operating.]]></summary></entry></feed>