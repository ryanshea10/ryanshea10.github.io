<!DOCTYPE html>
<html>
  <head>
    <title>Week 6 – Ryan Shea – DREAM Project</title>

        <meta charset="utf-8" />
    <meta content='text/html; charset=utf-8' http-equiv='Content-Type'>
    <meta http-equiv='X-UA-Compatible' content='IE=edge'>
    <meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1.0'>

    
    <meta name="description" content="During week six I worked on trying to fix the issue with BlenderBot 2 involving multiple concurrent users. Unfortunately the issue seemed to stem from an issue inherent in the library that we are using to set up the chat service for BlenderBot 2. Instead I created a work around which involves using a queue to handle chat requests. With this method the bot will only respond to one message at a timeand therefore the issues related to concurrent users won’t occur. This had the added benefit on keeping the services memory at a minimum as it will not be using as many resources in parallel. On the other hand, if there are many users chatting at once this method could be problematic since the bot’s response time will grow with more people in the queue. This presents a pretty big issue in terms of scalability and will likely need to be fixed at some point. I am planning to reach out to the team who wrote the library to try and resolve this issue while continuing to work on other bots using the workaround in the meantime.
" />
    <meta property="og:description" content="During week six I worked on trying to fix the issue with BlenderBot 2 involving multiple concurrent users. Unfortunately the issue seemed to stem from an issue inherent in the library that we are using to set up the chat service for BlenderBot 2. Instead I created a work around which involves using a queue to handle chat requests. With this method the bot will only respond to one message at a timeand therefore the issues related to concurrent users won’t occur. This had the added benefit on keeping the services memory at a minimum as it will not be using as many resources in parallel. On the other hand, if there are many users chatting at once this method could be problematic since the bot’s response time will grow with more people in the queue. This presents a pretty big issue in terms of scalability and will likely need to be fixed at some point. I am planning to reach out to the team who wrote the library to try and resolve this issue while continuing to work on other bots using the workaround in the meantime.
" />
    
    <meta name="author" content="Ryan Shea" />

    
    <meta property="og:title" content="Week 6" />
    <meta property="twitter:title" content="Week 6" />
    

    <!--[if lt IE 9]>
      <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="alternate" type="application/rss+xml" title="Ryan Shea - DREAM Project" href="/feed.xml" />

    <!-- Created with Jekyll Now - http://github.com/barryclark/jekyll-now -->
  </head>

  <body>
    <div class="wrapper-masthead">
      <div class="container">
        <header class="masthead clearfix">
          <a href="/" class="site-avatar"><img src="https://ryanshea10.github.io/images/RPS_Photo.png" /></a>

          <div class="site-info">
            <h1 class="site-name"><a href="/">Ryan Shea</a></h1>
            <p class="site-description">DREAM Project</p>
          </div>

        </header>
      </div>
    </div>

    <div id="main" role="main" class="container">
      <article class="post">
  <h1>Week 6</h1>

  <div class="entry">
    <p>During week six I worked on trying to fix the issue with BlenderBot 2 involving multiple concurrent users. Unfortunately the issue seemed to stem from an issue inherent in the library that we are using to set up the chat service for BlenderBot 2. Instead I created a work around which involves using a queue to handle chat requests. With this method the bot will only respond to one message at a timeand therefore the issues related to concurrent users won’t occur. This had the added benefit on keeping the services memory at a minimum as it will not be using as many resources in parallel. On the other hand, if there are many users chatting at once this method could be problematic since the bot’s response time will grow with more people in the queue. This presents a pretty big issue in terms of scalability and will likely need to be fixed at some point. I am planning to reach out to the team who wrote the library to try and resolve this issue while continuing to work on other bots using the workaround in the meantime.</p>

  </div>

  <div class="date">
    Written on July  1, 2022
  </div>

</article>

    </div>

    <div class="wrapper-footer">
      <div class="container">
        <footer class="footer">
          
<a href="mailto:ryanshea10@gmail.com"><i class="svg-icon email"></i></a>











        </footer>
      </div>
    </div>

  </body>
</html>
